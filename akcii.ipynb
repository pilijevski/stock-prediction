{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0bgSkncOLAd"
      },
      "outputs": [],
      "source": [
        "# Install yfinance library\n",
        "%pip install -q yfinance --upgrade --no-cache-dir\n",
        "%pip install -q pandas==1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OjFe06f9ORC9"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import bs4 as bs\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from lib.utils.helpers import get_stock_symbols, extract_numerical_columns, get_snp_companies, get_cols_to_be_divided_by_total_assets\n",
        "from lib.utils.stocks import get_meta_data\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dPDxYkR_TMBu"
      },
      "outputs": [],
      "source": [
        "stocks = pd.read_csv(\"./lib/quarterly_statements.csv\",index_col=0, parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "utIjIM6d2sIv"
      },
      "outputs": [],
      "source": [
        "# getting all top 1500 US companies \n",
        "stock_symbols = get_stock_symbols()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ru5pK5AXT4tp"
      },
      "outputs": [],
      "source": [
        "stocks = stocks.loc['2021-01-01':]\n",
        "stocks = stocks.loc[stocks.ticker.isin(stock_symbols)]\n",
        "stocks['end_of_quarter'] = stocks.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aIRZWJxA38RS"
      },
      "outputs": [],
      "source": [
        "# meta_df = get_meta_data(stock_symbols=stock_symbols, stocks=stocks)\n",
        "# meta_df.to_csv('meta_df_2020.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bfffIMP9vffk"
      },
      "outputs": [],
      "source": [
        "meta_df = pd.read_csv('meta_df_2020.csv')\n",
        "meta_df.end_of_quarter = pd.to_datetime(meta_df.end_of_quarter)\n",
        "df = pd.merge(stocks, meta_df, how='left', on=['ticker', 'end_of_quarter'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df.to_csv('stocks_processed_2020.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cnjys0s7GT90"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('stocks_processed_2020.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove commas from thousands, and replace values that have only '-' with nan\n",
        "tmp = df['end_of_quarter'].copy()\n",
        "for col in list(df.columns):\n",
        "  try:\n",
        "    df.loc[:, col] = df.loc[:, col].str.replace(',', '').replace(r'^-$', np.nan, regex=True)\n",
        "  except:\n",
        "    pass\n",
        "# all percentage columns, remove the percent sign\n",
        "percentage_columns = [col for col in df.columns if any(df[col].astype(str).str.contains('%'))]\n",
        "for col in percentage_columns:\n",
        "  df.loc[:, col] = df.loc[:, col].str.replace('%', '')\n",
        "df['end_of_quarter'] = tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# selecting only numerical features, we need them for normalization, etc. 'increase' is also a numerical, but we dont modify it since it is our target\n",
        "numerical_columns = extract_numerical_columns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HaKE_P2A-xMG"
      },
      "outputs": [],
      "source": [
        "# we take all data since 2021 (we skip earlier years due covid effects) \n",
        "df = df.loc[df.end_of_quarter > '2021-01-01']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M6zGOrfTHNQW"
      },
      "outputs": [],
      "source": [
        "df['end_of_quarter'] = pd.to_datetime(df['end_of_quarter'])\n",
        "df['quarter_year'] = df['end_of_quarter'].dt.to_period('Q')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_be_divided_by_total_assets = get_cols_to_be_divided_by_total_assets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E-QbR_VSKHvl"
      },
      "outputs": [],
      "source": [
        "# converting all numerical values from string to float\n",
        "df[numerical_columns] = df[numerical_columns].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[cols_to_be_divided_by_total_assets] = df[cols_to_be_divided_by_total_assets].values / df['Total Assets'].values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GTkqYPbGRKgW"
      },
      "outputs": [],
      "source": [
        "# Mean normalization of all numerical values. As suggested by finance experts, we take the mean and the standard deviation of the industry per quarter for normalization\n",
        "numerical_columns.remove('increase') # removing the target variable, we dont want to normalize that value\n",
        "df_mean = df.groupby(['quarter_year', 'industry']).mean()\n",
        "df_std = df.groupby(['quarter_year', 'industry']).std()\n",
        "dff = pd.merge(left=df, right=df_mean, how='left', on=['quarter_year', 'industry'], suffixes=[\"\", \"_mean\"])\n",
        "dff = pd.merge(left=dff, right=df_std, how='left', on=['quarter_year', 'industry'], suffixes=[\"\", \"_std\"])\n",
        "\n",
        "for col in numerical_columns:\n",
        "  dff[col] = (dff[col] - dff[col + \"_mean\"]) / dff[col + \"_std\"]\n",
        "df = dff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "y7emmeFS4j-e"
      },
      "outputs": [],
      "source": [
        "# One hot encoding of industry, we skip encoding of sector since we have almost all NaNs there\n",
        "one_hot_encoded_industry = pd.get_dummies(df['industry'], prefix='industry')\n",
        "# one_hot_encoded_sector = pd.get_dummies(df['sector'], prefix='sector')\n",
        "df = pd.concat([df, one_hot_encoded_industry], axis=1)\n",
        "df.drop(['industry', 'sector'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFgo38RbdB59",
        "outputId": "09826306-4bf9-451c-be32-a725ad6a1d86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.287690168494993, -0.7172177799983862)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.increase.max(), df.increase.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VBw1Zcs_pB5i"
      },
      "outputs": [],
      "source": [
        "# where target variable 'increase' does not exists, remove those rows\n",
        "df.dropna(axis=0, inplace=True, subset=['increase'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUwGYBzLOaN-",
        "outputId": "ddf91d0c-35e4-4569-f54c-551ef876459b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14971, 569), (1486, 569))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train test split (we leave the last quarter for test)\n",
        "df_test = df.groupby('ticker', as_index=False).first()\n",
        "df_train = df.loc[~df.end_of_quarter.isin(list(df_test.end_of_quarter.values))]\n",
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rzwXDiu3QRdh"
      },
      "outputs": [],
      "source": [
        "y_train = df_train[['increase', 'ticker']]\n",
        "y_test = df_test[['increase', 'ticker']]\n",
        "df_test = df_test.drop(['ticker', 'end_of_quarter', 'increase', 'quarter_year'], axis=1)\n",
        "df_train = df_train.drop(['ticker', 'end_of_quarter', 'increase',  'quarter_year'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3Yvm7hLA-fwh"
      },
      "outputs": [],
      "source": [
        "# going from real valued 'increase' to classification problem\n",
        "y_train['increase_real_values'] = y_train.increase\n",
        "class_thresholds = [-0.1, 0.0, 0.1, 0.2]\n",
        "y_train.increase[y_train.increase_real_values >= class_thresholds[3]] = 4\n",
        "y_train.increase[(y_train.increase_real_values >= class_thresholds[2]) & (y_train.increase_real_values < class_thresholds[3])] = 3\n",
        "y_train.increase[(y_train.increase_real_values >= class_thresholds[1]) & (y_train.increase_real_values < class_thresholds[2])] = 2\n",
        "y_train.increase[(y_train.increase_real_values > class_thresholds[0]) & (y_train.increase_real_values < class_thresholds[1])] = 1\n",
        "y_train.increase[y_train.increase_real_values <= class_thresholds[0]] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdxex-p9ErW9",
        "outputId": "590ebff6-a53c-4bee-dc6a-27069c7cc8d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0.0: 3541, 1.0: 3963, 2.0: 3723, 3.0: 2158, 4.0: 1586}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_counts = dict(zip(*np.unique(y_train.increase.values, return_counts=True)))\n",
        "class_weights = {class_label: len(y_train.increase.values) / (len(np.unique(y_train.increase.values)) * count) for class_label, count in class_counts.items()}\n",
        "class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bPkVGKfnIh7-"
      },
      "outputs": [],
      "source": [
        "# We fill all NaN values with maxint from numpy. Currently, we are not sure if this is financially correct (?)\n",
        "df_train.fillna(np.iinfo('int').max, inplace=True)\n",
        "df_test.fillna(np.iinfo('int').max, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7-5gQtvnvtQg"
      },
      "outputs": [],
      "source": [
        "# Assuming you have your features (x) and labels (y) ready, split the data.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "odVqvRHgwJki",
        "outputId": "c605c3ab-f2e7-41a3-a4b5-6ef82781503f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=20, n_estimators=1000, random_state=42)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We fit a classifier to predict the increase in percentage into the next Q\n",
        "rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=20)#, class_weight=class_weights)\n",
        "# Fit the model to the training data\n",
        "rf_classifier.fit(X_train, Y_train.increase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "DMJb3UBdzOB0",
        "outputId": "36636fed-6f92-4cf5-9e8b-4486b8803a8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>preds</th>\n",
              "      <th>true</th>\n",
              "      <th>increase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14552</th>\n",
              "      <td>GPS</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.171251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11954</th>\n",
              "      <td>AXL</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.139092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6410</th>\n",
              "      <td>IBP</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.076306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6044</th>\n",
              "      <td>PR</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.621429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10714</th>\n",
              "      <td>UPBD</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.285551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5798</th>\n",
              "      <td>DECK</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.279550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14445</th>\n",
              "      <td>GDEN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.074520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>TJX</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.118934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11161</th>\n",
              "      <td>ALL</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.095479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9878</th>\n",
              "      <td>ACLS</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.706394</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ticker  preds  true  increase\n",
              "14552    GPS    4.0   3.0  0.171251\n",
              "11954    AXL    4.0   3.0  0.139092\n",
              "6410     IBP    4.0   2.0  0.076306\n",
              "6044      PR    4.0   4.0  0.621429\n",
              "10714   UPBD    4.0   4.0  0.285551\n",
              "5798    DECK    4.0   4.0  0.279550\n",
              "14445   GDEN    4.0   2.0  0.074520\n",
              "3863     TJX    4.0   3.0  0.118934\n",
              "11161    ALL    4.0   2.0  0.095479\n",
              "9878    ACLS    4.0   4.0  0.706394"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict on the test set just as sanity check\n",
        "rf_classifier.predict(X_test)\n",
        "ticker = Y_test.ticker\n",
        "p = pd.DataFrame({\"ticker\": ticker, \"preds\": rf_classifier.predict(X_test), \"true\": Y_test.increase, \"increase\": Y_test.increase_real_values})\n",
        "# Select the top K stocks that we would invest (still this data is older, just for sanity check and to check for underfitting)\n",
        "K = 10\n",
        "p.sort_values(by='preds')[::-1].iloc[:K]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z12eAQWVBnG1",
        "outputId": "ffcc99d0-c713-4bed-e94e-26bfe3603f01"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>pred_counts</th>\n",
              "      <th>true_counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>446</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>429</td>\n",
              "      <td>359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>412</td>\n",
              "      <td>357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>106</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>105</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   value  pred_counts  true_counts\n",
              "0    2.0          446          411\n",
              "1    1.0          429          359\n",
              "2    0.0          412          357\n",
              "3    3.0          106          216\n",
              "4    4.0          105          155"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Distribution sanity check\n",
        "pd.DataFrame({\"value\": p.preds.value_counts().index, \"pred_counts\": p.preds.value_counts().values, \"true_counts\": p.true.value_counts().values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhoWwKKA_u9O",
        "outputId": "12094c2c-716e-4f2f-a35e-e89a11fe49a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.40186915887850466\n",
            "Confusion matrix: \n",
            " [[199 104  35  12   9]\n",
            " [101 165 112  21  12]\n",
            " [ 52  96 167  26  16]\n",
            " [ 28  42  91  29  26]\n",
            " [ 32  22  41  18  42]]\n"
          ]
        }
      ],
      "source": [
        "# Compute accuracy\n",
        "accuracy = accuracy_score(p.true, p.preds)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(f'Confusion matrix: \\n {confusion_matrix(p.true, p.preds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "DgK43n36KvU5",
        "outputId": "c46f2b8c-4d08-458a-e8d7-3bfa0ddab072"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>preds</th>\n",
              "      <th>increase</th>\n",
              "      <th>proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>ANET</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.319264</td>\n",
              "      <td>0.308524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>STX</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.040061</td>\n",
              "      <td>0.266858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>807</th>\n",
              "      <td>LRCX</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.228965</td>\n",
              "      <td>0.238151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218</th>\n",
              "      <td>SMCI</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.732703</td>\n",
              "      <td>0.229440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>853</th>\n",
              "      <td>META</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.459776</td>\n",
              "      <td>0.229058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1422</th>\n",
              "      <td>WDC</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.247279</td>\n",
              "      <td>0.225324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>CMG</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.295400</td>\n",
              "      <td>0.219753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ticker  preds  increase     proba\n",
              "90     ANET    4.0  0.319264  0.308524\n",
              "1257    STX    4.0  0.040061  0.266858\n",
              "807    LRCX    4.0  0.228965  0.238151\n",
              "1218   SMCI    4.0  2.732703  0.229440\n",
              "853    META    4.0  0.459776  0.229058\n",
              "1422    WDC    4.0  0.247279  0.225324\n",
              "290     CMG    4.0  0.295400  0.219753"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "proba = rf_classifier.predict_proba(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))])[rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))])== np.max(rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))]))][:, -1]\n",
        "# predicting on the SNP 500 stocks\n",
        "p = pd.DataFrame({\"ticker\": y_test.loc[y_test.ticker.isin(get_snp_companies('500'))].ticker, \"preds\": rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))]), \"increase\": y_test.increase.loc[y_test.ticker.isin(get_snp_companies('500'))]})\n",
        "# selecting the top K stocks we want to put money in\n",
        "p[p.preds == np.max(p.preds.values)]\n",
        "b = p[p.preds == np.max(p.preds.values)]\n",
        "b['proba'] = proba\n",
        "b.sort_values(by='proba')[::-1].iloc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3oV_WmOmksN5",
        "outputId": "56240586-633f-41b4-a7f6-9c87b57e2f90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'We have gain (positive) or loss (negative) of 61.763554896821006% on the invested 10 stocks'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f'We have gain (positive) or loss (negative) of {b.sort_values(by=\"proba\")[::-1].iloc[:10].increase.mean()  * 100}% on the invested 10 stocks'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ErNekIbECi8z"
      },
      "outputs": [],
      "source": [
        "p['increase_q'] = p.increase\n",
        "class_thresholds = [-0.1, 0.0, 0.1, 0.2]\n",
        "p.increase_q[p.increase >= class_thresholds[3]] = 4\n",
        "p.increase_q[(p.increase >= class_thresholds[2]) & (p.increase_real_values < class_thresholds[3])] = 3\n",
        "p.increase_q[(p.increase >= class_thresholds[1]) & (p.increase < class_thresholds[2])] = 2\n",
        "p.increase_q[(p.increase > class_thresholds[0]) & (p.increase < class_thresholds[1])] = 1\n",
        "p.increase_q[p.increase <= class_thresholds[0]] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA3hVdYVdROt",
        "outputId": "3e3c84b6-5027-4704-a705-3cd462d4c1cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 0.3587174348697395\n",
            "Confusion matrix on test set: \n",
            " [[21 15  7  0  0]\n",
            " [10 73 38  0  0]\n",
            " [25 55 77  2  1]\n",
            " [ 8 37 62  2  0]\n",
            " [ 7 19 32  2  6]]\n"
          ]
        }
      ],
      "source": [
        "# Compute accuracy on test\n",
        "accuracy = accuracy_score(p.increase_q, p.preds)\n",
        "print(\"Accuracy on test set:\", accuracy)\n",
        "print(f'Confusion matrix on test set: \\n {confusion_matrix(p.increase_q, p.preds)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### From here downwards, all the cells are concatenated and we run experiments from 2021-07-01 to today"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "quartals = ['2021-07-01', '2021-10-01',\n",
        "            '2022-01-01', '2022-04-01', '2022-07-01', '2022-10-01',\n",
        "            '2023-01-01', '2023-04-01', '2023-07-01', '2023-10-01',\n",
        "            '2024-01-01']\n",
        "accuracies = {}\n",
        "for quartal in quartals:\n",
        "    df = pd.read_csv('stocks_processed_2020.csv')\n",
        "    # remove commas from thousands, and replace values that have only '-' with nan\n",
        "    tmp = df['end_of_quarter'].copy()\n",
        "    for col in list(df.columns):\n",
        "        try:\n",
        "            df.loc[:, col] = df.loc[:, col].str.replace(',', '').replace(r'^-$', np.nan, regex=True)\n",
        "        except:\n",
        "            pass\n",
        "    # all percentage columns, remove the percent sign\n",
        "    percentage_columns = [col for col in df.columns if any(df[col].astype(str).str.contains('%'))]\n",
        "    for col in percentage_columns:\n",
        "        df.loc[:, col] = df.loc[:, col].str.replace('%', '')\n",
        "    df['end_of_quarter'] = tmp\n",
        "    # selecting only numerical features, we need them for normalization, etc. 'increase' is also a numerical, but we dont modify it since it is our target\n",
        "    numerical_columns = extract_numerical_columns(df)\n",
        "    # we take all data since 2021 (we skip earlier years due covid effects) \n",
        "    df = df.loc[(df.end_of_quarter > '2020-01-01') & (df.end_of_quarter < quartal)]\n",
        "    df['end_of_quarter'] = pd.to_datetime(df['end_of_quarter'])\n",
        "    df['quarter_year'] = df['end_of_quarter'].dt.to_period('Q')\n",
        "    # cols_to_be_divided_by_total_assets = get_cols_to_be_divided_by_total_assets()\n",
        "    # converting all numerical values from string to float\n",
        "    df[numerical_columns] = df[numerical_columns].astype('float')\n",
        "    # df[cols_to_be_divided_by_total_assets] = df[cols_to_be_divided_by_total_assets].values / df['Total Assets'].values.reshape(-1, 1)\n",
        "    # Mean normalization of all numerical values. As suggested by finance experts, we take the mean and the standard deviation of the industry per quarter for normalization\n",
        "    numerical_columns.remove('increase') # removing the target variable, we dont want to normalize that value\n",
        "    df_mean = df.groupby(['quarter_year', 'industry']).mean()\n",
        "    df_std = df.groupby(['quarter_year', 'industry']).std()\n",
        "    dff = pd.merge(left=df, right=df_mean, how='left', on=['quarter_year', 'industry'], suffixes=[\"\", \"_mean\"])\n",
        "    dff = pd.merge(left=dff, right=df_std, how='left', on=['quarter_year', 'industry'], suffixes=[\"\", \"_std\"])\n",
        "\n",
        "    for col in numerical_columns:\n",
        "        dff[col] = (dff[col] - dff[col + \"_mean\"]) / dff[col + \"_std\"]\n",
        "    df = dff\n",
        "    # One hot encoding of industry, we skip encoding of sector since we have almost all NaNs there\n",
        "    one_hot_encoded_industry = pd.get_dummies(df['industry'], prefix='industry')\n",
        "    # one_hot_encoded_sector = pd.get_dummies(df['sector'], prefix='sector')\n",
        "    df = pd.concat([df, one_hot_encoded_industry], axis=1)\n",
        "    df.drop(['industry', 'sector'], axis=1, inplace=True)\n",
        "    df.increase.max(), df.increase.min()\n",
        "    # where target variable 'increase' does not exists, remove those rows\n",
        "    df.dropna(axis=0, inplace=True, subset=['increase'])\n",
        "    # train test split (we leave the last quarter for test)\n",
        "    df_test = df.groupby('ticker', as_index=False).first()\n",
        "    df_train = df.loc[~df.end_of_quarter.isin(list(df_test.end_of_quarter.values))]\n",
        "    df_train.shape, df_test.shape\n",
        "    y_train = df_train[['increase', 'ticker']]\n",
        "    y_test = df_test[['increase', 'ticker']]\n",
        "    df_test = df_test.drop(['ticker', 'end_of_quarter', 'increase', 'quarter_year'], axis=1)\n",
        "    df_train = df_train.drop(['ticker', 'end_of_quarter', 'increase',  'quarter_year'], axis=1)\n",
        "    # going from real valued 'increase' to classification problem\n",
        "    y_train['increase_real_values'] = y_train.increase\n",
        "    class_thresholds = [-0.1, 0.0, 0.1, 0.2]\n",
        "    y_train.increase[y_train.increase_real_values >= class_thresholds[3]] = 4\n",
        "    y_train.increase[(y_train.increase_real_values >= class_thresholds[2]) & (y_train.increase_real_values < class_thresholds[3])] = 3\n",
        "    y_train.increase[(y_train.increase_real_values >= class_thresholds[1]) & (y_train.increase_real_values < class_thresholds[2])] = 2\n",
        "    y_train.increase[(y_train.increase_real_values > class_thresholds[0]) & (y_train.increase_real_values < class_thresholds[1])] = 1\n",
        "    y_train.increase[y_train.increase_real_values <= class_thresholds[0]] = 0\n",
        "    class_counts = dict(zip(*np.unique(y_train.increase.values, return_counts=True)))\n",
        "    class_weights = {class_label: len(y_train.increase.values) / (len(np.unique(y_train.increase.values)) * count) for class_label, count in class_counts.items()}\n",
        "    class_counts\n",
        "    # We fill all NaN values with maxint from numpy. Currently, we are not sure if this is financially correct (?)\n",
        "    df_train.fillna(np.iinfo('int').max, inplace=True)\n",
        "    df_test.fillna(np.iinfo('int').max, inplace=True)\n",
        "    # Assuming you have your features (x) and labels (y) ready, split the data.\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(df_train, y_train, test_size=0.1, random_state=42)\n",
        "    # We fit a classifier to predict the increase in percentage into the next Q\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=20)#, class_weight=class_weights)\n",
        "    # Fit the model to the training data\n",
        "    rf_classifier.fit(X_train, Y_train.increase)\n",
        "    # Predict on the test set just as sanity check\n",
        "    rf_classifier.predict(X_test)\n",
        "    ticker = Y_test.ticker\n",
        "    p = pd.DataFrame({\"ticker\": ticker, \"preds\": rf_classifier.predict(X_test), \"true\": Y_test.increase, \"increase\": Y_test.increase_real_values})\n",
        "    # Select the top K stocks that we would invest (still this data is older, just for sanity check and to check for underfitting)\n",
        "    K = 10\n",
        "    p.sort_values(by='preds')[::-1].iloc[:K]\n",
        "    # Distribution sanity check\n",
        "    # pd.DataFrame({\"value\": p.preds.value_counts().index, \"pred_counts\": p.preds.value_counts().values, \"true_counts\": p.true.value_counts().values})\n",
        "    # Compute accuracy\n",
        "    accuracy = accuracy_score(p.true, p.preds)\n",
        "    \n",
        "    # print(\"Accuracy:\", accuracy)\n",
        "    # print(f'Confusion matrix: \\n {confusion_matrix(p.true, p.preds)}')\n",
        "    proba = rf_classifier.predict_proba(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))])[rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))])== np.max(rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))]))][:, -1]\n",
        "    # predicting on the SNP 500 stocks\n",
        "    p = pd.DataFrame({\"ticker\": y_test.loc[y_test.ticker.isin(get_snp_companies('500'))].ticker, \"preds\": rf_classifier.predict(df_test.loc[y_test.ticker.isin(get_snp_companies('500'))]), \"increase\": y_test.increase.loc[y_test.ticker.isin(get_snp_companies('500'))]})\n",
        "    # selecting the top K stocks we want to put money in\n",
        "    p[p.preds == np.max(p.preds.values)]\n",
        "    b = p[p.preds == np.max(p.preds.values)]\n",
        "    b['proba'] = proba\n",
        "    b.sort_values(by='proba')[::-1].iloc[:10]\n",
        "    f'We have gain (positive) or loss (negative) of {b.sort_values(by=\"proba\")[::-1].iloc[:10].increase.mean()  * 100}% on the invested 10 stocks'\n",
        "    p['increase_q'] = p.increase\n",
        "    class_thresholds = [-0.1, 0.0, 0.1, 0.2]\n",
        "    p.increase_q[p.increase >= class_thresholds[3]] = 4\n",
        "    p.increase_q[(p.increase >= class_thresholds[2]) & (p.increase < class_thresholds[3])] = 3\n",
        "    p.increase_q[(p.increase >= class_thresholds[1]) & (p.increase < class_thresholds[2])] = 2\n",
        "    p.increase_q[(p.increase > class_thresholds[0]) & (p.increase < class_thresholds[1])] = 1\n",
        "    p.increase_q[p.increase <= class_thresholds[0]] = 0\n",
        "    # Compute accuracy on test\n",
        "    test_accuracy = accuracy_score(p.increase_q, p.preds)\n",
        "    # print(\"Accuracy on test set:\", test_accuracy)\n",
        "    accuracies[quartal] = {\"val\":accuracy, \"test\": test_accuracy, \"gain\": f'{b.sort_values(by=\"proba\")[::-1].iloc[:10].increase.mean()  * 100}%'}\n",
        "    # print(f'Confusion matrix on test set: \\n {confusion_matrix(p.increase_q, p.preds)}')\n",
        "    print(accuracies[quartal])\n",
        "    print(\"######################\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The summed gain over the quartals is:  187.8494084891033 %\n",
            "Starting with 1000 USD, over 11 quartals, we will end up with 5141.5545480509045 USD\n",
            "Starting with 1000 USD, over 11 quartals, if we add 2100 USD plus every quartal, we will end up with 63631.69498059065 USD\n",
            "Out of 63631.69498059065 USD, our investment accounts 24100, while the gain accounts for 39531.69498059065\n"
          ]
        }
      ],
      "source": [
        "suma =  0\n",
        "capital = 1000\n",
        "start_capital = capital\n",
        "for k in accuracies:\n",
        "    suma += float(accuracies[k]['gain'][:-1])\n",
        "    capital += capital * float(accuracies[k]['gain'][:-1]) / 100\n",
        "\n",
        "print(\"The summed gain over the quartals is: \", suma, \"%\")\n",
        "print(f'Starting with {start_capital} USD, over {len(accuracies)} quartals, we will end up with {capital} USD')\n",
        "\n",
        "suma =  0\n",
        "capital = 1000\n",
        "reinvestment_every_quartal = 2100\n",
        "start_capital = capital\n",
        "for k in accuracies:\n",
        "    suma += float(accuracies[k]['gain'][:-1])\n",
        "    capital += capital * float(accuracies[k]['gain'][:-1]) / 100 + reinvestment_every_quartal\n",
        "\n",
        "print(f'Starting with {start_capital} USD, over {len(accuracies)} quartals, if we add {reinvestment_every_quartal} USD plus every quartal, we will end up with {capital} USD')\n",
        "print(f'Out of {capital} USD, our investment accounts {start_capital + reinvestment_every_quartal *len(accuracies)}, while the gain accounts for {capital - (start_capital + reinvestment_every_quartal *len(accuracies))}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BYCCKmKXewNI",
        "outputId": "57b3fab5-0074-4dcb-eaa0-4611e8dd0188"
      },
      "outputs": [],
      "source": [
        "importances = rf_classifier.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in rf_classifier.estimators_], axis=0)\n",
        "\n",
        "forest_importances = pd.Series(importances, index=list(df_train.columns))\n",
        "plt.figure(figsize=(16,16))\n",
        "fig, ax = plt.subplots(figsize=(30,30))\n",
        "forest_importances.plot.bar(yerr=std, ax=ax)\n",
        "ax.set_title(\"Feature importances using MDI\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()\n",
        "plt.savefig('feature_importances_plot.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
